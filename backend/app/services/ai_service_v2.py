"""
AI æœåŠ¡ v2.1 - æ€§èƒ½ä¼˜åŒ–ç‰ˆ

æ ¸å¿ƒç­–ç•¥ï¼š
1. ä¼˜å…ˆä½¿ç”¨AIç”Ÿæˆå†…å®¹
2. éªŒè¯AIç”Ÿæˆå†…å®¹è´¨é‡
3. ä¸åˆæ ¼åˆ™ä½¿ç”¨ç´ æåº“é™çº§
4. ç¡®ä¿æ¸¸æˆå§‹ç»ˆæœ‰é«˜è´¨é‡å†…å®¹

æ€§èƒ½ä¼˜åŒ–ï¼š
- é™ä½max_tokensï¼ˆåˆå§‹2048ï¼Œå›åˆ1024ï¼‰
- é™ä½temperatureï¼ˆ0.7ï¼‰æå‡é€Ÿåº¦
- ç¼“å­˜æœºåˆ¶ï¼ˆç›¸åŒè¯·æ±‚ç›´æ¥è¿”å›ï¼‰
- ç¼©çŸ­timeoutï¼ˆ20ç§’ï¼‰

é…ç½®ï¼š
- model: gemini-2.0-flash-lite
- temperature: 0.7ï¼ˆå¹³è¡¡åˆ›æ„å’Œé€Ÿåº¦ï¼‰
- max_tokens: 2048ï¼ˆåˆå§‹ï¼‰/ 1024ï¼ˆå›åˆï¼‰
"""
import json
import random
import re
import time
from functools import wraps
from typing import Literal, Optional
from openai import AsyncOpenAI
from loguru import logger
from hashlib import md5

from app.core.config import settings
from app.prompts.fallback_library import (
    get_random_company,
    get_random_npcs,
    get_random_magical_element,
    get_style_by_name,
    FALLBACK_STYLES,
)
from app.prompts.system_prompt import build_user_prompt
from app.services.content_validator import ContentValidator


# ç®€å•çš„å†…å­˜ç¼“å­˜ï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®ç”¨Redisï¼‰
_cache: dict[str, dict] = {}
_CACHE_MAX_SIZE = 100
_CACHE_TTL = 3600  # 1å°æ—¶ç¼“å­˜


# æ€§èƒ½ç›‘æ§è£…é¥°å™¨
def log_execution_time(func_name: str):
    """è£…é¥°å™¨ï¼šè®°å½•å‡½æ•°æ‰§è¡Œæ—¶é—´"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = await func(*args, **kwargs)
                elapsed = time.time() - start_time
                logger.info(f"â±ï¸ {func_name} è€—æ—¶: {elapsed:.3f}ç§’")
                return result
            except Exception as e:
                elapsed = time.time() - start_time
                logger.error(f"âŒ {func_name} å¤±è´¥ (è€—æ—¶{elapsed:.3f}ç§’): {e}")
                raise
        return wrapper
    return decorator


class AIServiceV2:
    """
    AIæœåŠ¡ç±»ï¼ˆv2 - æ··åˆæ¨¡å¼ï¼‰

    èŒè´£ï¼š
    - è°ƒç”¨OpenAI API
    - éªŒè¯AIç”Ÿæˆå†…å®¹
    - ç´ æåº“é™çº§
    - å“åº”è§£æ
    """

    # æ¨¡å‹é…ç½®ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰
    MODEL: str = "gemini-2.0-flash-lite"
    TEMPERATURE: float = 0.7  # é™ä½æ¸©åº¦æå‡é€Ÿåº¦ï¼ˆ0.7è¶³å¤Ÿåˆ›æ„ï¼‰
    MAX_TOKENS_INITIAL: int = 2048  # åˆå§‹ç”Ÿæˆç”¨2048å¤Ÿç”¨ï¼ˆåŸæ¥8192å¤ªSBäº†ï¼‰
    MAX_TOKENS_TURN: int = 1024  # åç»­å›åˆç”¨1024å¤Ÿç”¨

    # å•ä¾‹å®ä¾‹ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼šé¿å…é‡å¤åˆ›å»ºclientï¼‰
    _instance: Optional['AIServiceV2'] = None
    _client: Optional[AsyncOpenAI] = None

    def __new__(cls):
        """å•ä¾‹æ¨¡å¼ï¼šå…¨å±€åªåˆ›å»ºä¸€ä¸ªAIServiceå®ä¾‹"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            logger.info("ğŸ¤– AIæœåŠ¡å•ä¾‹åˆ›å»º")
        return cls._instance

    def __init__(self):
        """åˆå§‹åŒ–AIæœåŠ¡ï¼ˆå•ä¾‹æ¨¡å¼ï¼Œåªä¼šåˆå§‹åŒ–ä¸€æ¬¡ï¼‰"""
        # é¿å…é‡å¤åˆå§‹åŒ–
        if hasattr(self, '_initialized') and self._initialized:
            return

        if not settings.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY æœªé…ç½®")

        # å…¨å±€å…±äº«çš„clientå®ä¾‹ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
        if AIServiceV2._client is None:
            AIServiceV2._client = AsyncOpenAI(
                api_key=settings.OPENAI_API_KEY,
                base_url=settings.OPENAI_BASE_URL if settings.OPENAI_BASE_URL else None
            )

        self.client = AIServiceV2._client

        # ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹ï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤
        self.model = getattr(settings, 'OPENAI_MODEL', self.MODEL)
        self.temperature = getattr(settings, 'OPENAI_TEMPERATURE', self.TEMPERATURE)

        # åˆå§‹åŒ–éªŒè¯å™¨
        self.validator = ContentValidator()

        self._initialized = True
        logger.info(f"ğŸš€ AIæœåŠ¡åˆå§‹åŒ– - æ¨¡å‹: {self.model}, æ¸©åº¦: {self.temperature}")

    @staticmethod
    def _make_cache_key(*args) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_str = "|".join(str(arg) for arg in args)
        return md5(key_str.encode()).hexdigest()

    @staticmethod
    def _get_cache(key: str) -> Optional[dict]:
        """è·å–ç¼“å­˜"""
        return _cache.get(key)

    @staticmethod
    def _set_cache(key: str, value: dict) -> None:
        """è®¾ç½®ç¼“å­˜ï¼ˆLRUç­–ç•¥ï¼‰"""
        global _cache
        # è¶…è¿‡æœ€å¤§ç¼“å­˜æ•°ï¼Œåˆ é™¤æœ€æ—©çš„
        if len(_cache) >= _CACHE_MAX_SIZE:
            oldest_key = next(iter(_cache))
            del _cache[oldest_key]
        _cache[key] = value

    @log_execution_time("AIç”Ÿæˆåˆå§‹å›åˆ")
    async def generate_initial_turn(
        self,
        player_name: str,
        difficulty: str,
        seed: int
    ) -> dict:
        """
        ç”Ÿæˆåˆå§‹å›åˆå†…å®¹ï¼ˆæ··åˆç­–ç•¥ï¼šAIç”Ÿæˆ â†’ éªŒè¯ â†’ é™çº§ï¼‰

        æ€§èƒ½ä¼˜åŒ–ï¼š
        1. ç¼“å­˜ç›¸åŒè¯·æ±‚
        2. é™ä½max_tokensï¼ˆ2048ï¼‰
        3. é™ä½temperatureï¼ˆ0.7ï¼‰
        4. ç¼©çŸ­timeoutï¼ˆ20ç§’ï¼‰

        Args:
            player_name: ç©å®¶åç§°
            difficulty: éš¾åº¦
            seed: éšæœºç§å­

        Returns:
            AIç”Ÿæˆçš„å†…å®¹æˆ–ç´ æåº“é™çº§å†…å®¹
        """
        # æ£€æŸ¥ç¼“å­˜ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
        cache_key = self._make_cache_key("initial", player_name, difficulty, seed)
        cached_result = self._get_cache(cache_key)
        if cached_result:
            logger.info(f"ğŸ’¾ å‘½ä¸­ç¼“å­˜ - Seed: {seed}")
            return cached_result

        # è®¾ç½®éšæœºç§å­ï¼ˆä¿è¯åŒä¸€ä¼šè¯å†…è¾“å‡ºä¸€è‡´ï¼‰
        random.seed(seed)
        system_prompt = self._get_system_prompt()
        user_prompt = build_user_prompt(
            player_name=player_name,
            difficulty=difficulty,
            seed=seed,
            is_initial=True
        )

        # ç­–ç•¥1: å°è¯•AIç”Ÿæˆï¼ˆä¼˜åŒ–å‚æ•°ï¼‰
        try:
            api_start = time.time()
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=self.temperature,
                max_tokens=self.MAX_TOKENS_INITIAL,  # ä½¿ç”¨ä¼˜åŒ–åçš„2048
                timeout=20.0,  # ç¼©çŸ­è¶…æ—¶æ—¶é—´ï¼ˆåŸæ¥60ç§’å¤ªSBï¼‰
            )
            api_time = time.time() - api_start
            logger.info(f"âš¡ APIè°ƒç”¨è€—æ—¶: {api_time:.3f}ç§’")

            content = response.choices[0].message.content
            if not content:
                raise ValueError("AIè¿”å›äº†ç©ºå“åº”")

            # è§£æJSONå“åº”
            parse_start = time.time()
            result = self._parse_ai_response(content)
            parse_time = time.time() - parse_start
            logger.info(f"ğŸ” JSONè§£æè€—æ—¶: {parse_time:.3f}ç§’")

            # éªŒè¯AIç”Ÿæˆçš„å†…å®¹è´¨é‡
            validate_start = time.time()
            is_valid, errors = self.validator.validate_initial_response(result)
            validate_time = time.time() - validate_start
            logger.info(f"âœ… å†…å®¹éªŒè¯è€—æ—¶: {validate_time:.3f}ç§’")

            if is_valid:
                logger.success(f"âœ… AIç”Ÿæˆåˆå§‹å†…å®¹æˆåŠŸ - Seed: {seed}")
                # ç¼“å­˜ç»“æœ
                self._set_cache(cache_key, result)
                return result
            else:
                logger.warning(f"âš ï¸ AIå†…å®¹è´¨é‡ä¸åˆæ ¼ï¼Œä½¿ç”¨ç´ æåº“é™çº§: {errors}")
                return self._generate_fallback_initial(seed, player_name)

        except Exception as e:
            logger.warning(f"âš ï¸ AIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨ç´ æåº“é™çº§: {e}")
            return self._generate_fallback_initial(seed, player_name)

    @log_execution_time("AIç”Ÿæˆä¸‹ä¸€å›åˆ")
    async def generate_next_turn(
        self,
        context: list[dict],
        user_action: str,
        seed: int
    ) -> dict:
        """
        ç”Ÿæˆä¸‹ä¸€å›åˆå†…å®¹ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰

        æ€§èƒ½ä¼˜åŒ–ï¼š
        1. é™ä½max_tokensï¼ˆ1024ï¼‰
        2. ç¼©çŸ­timeoutï¼ˆ20ç§’ï¼‰

        Args:
            context: å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆmessages + summariesï¼‰
            user_action: ç©å®¶è¡ŒåŠ¨
            seed: éšæœºç§å­

        Returns:
            AIç”Ÿæˆçš„å†…å®¹
        """
        # è®¾ç½®éšæœºç§å­
        random.seed(seed)
        system_prompt = self._get_system_prompt()

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [{"role": "system", "content": system_prompt}]
        messages.extend(context)
        messages.append({
            "role": "user",
            "content": f"ç©å®¶é€‰æ‹©äº†: {user_action}\nè¯·æ ¹æ®è¿™ä¸ªé€‰æ‹©ç”Ÿæˆåç»­å‰§æƒ…å’Œæ–°çš„é€‰é¡¹ã€‚"
        })

        try:
            api_start = time.time()
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.MAX_TOKENS_TURN,  # ä½¿ç”¨ä¼˜åŒ–åçš„1024
                timeout=20.0,  # ç¼©çŸ­è¶…æ—¶æ—¶é—´
            )
            api_time = time.time() - api_start
            logger.info(f"âš¡ APIè°ƒç”¨è€—æ—¶: {api_time:.3f}ç§’")

            content = response.choices[0].message.content
            if not content:
                raise ValueError("AIè¿”å›äº†ç©ºå“åº”")

            # è§£æJSONå“åº”
            result = self._parse_ai_response(content)

            logger.success(f"âœ… AIç”Ÿæˆæ–°å›åˆ - Seed: {seed}")
            return result

        except Exception as e:
            logger.error(f"âŒ AIè°ƒç”¨å¤±è´¥: {e}")
            raise  # ä¸é™çº§ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸

    @log_execution_time("AIç”Ÿæˆæ‘˜è¦")
    async def create_summary(self, messages_text: str) -> str:
        """
        ç”Ÿæˆæ‘˜è¦ï¼ˆç”¨äºä¸Šä¸‹æ–‡å‹ç¼©ï¼‰

        Args:
            messages_text: éœ€è¦æ‘˜è¦çš„æ¶ˆæ¯æ–‡æœ¬

        Returns:
            æ‘˜è¦æ–‡æœ¬
        """
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ¸¸æˆæ‘˜è¦ä¸“å®¶ã€‚
è¯·å°†ä»¥ä¸‹æ¸¸æˆå¯¹è¯å†å²æµ“ç¼©ä¸ºä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼Œä¿ç•™ï¼š
1. å…³é”®æƒ…èŠ‚
2. ç©å®¶çš„ä¸»è¦é€‰æ‹©
3. å½“å‰çŠ¶æ€

æ‘˜è¦åº”è¯¥ç®€æ´ä½†ä¿¡æ¯å®Œæ•´ï¼Œç”¨äºåç»­AIé‡å»ºä¸Šä¸‹æ–‡ã€‚"""
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"è¯·æ‘˜è¦ä»¥ä¸‹å¯¹è¯ï¼š\n\n{messages_text}"},
                ],
                temperature=0.3,  # æ‘˜è¦ä½¿ç”¨è¾ƒä½æ¸©åº¦
                max_tokens=500,
                timeout=15.0,
            )

            summary = response.choices[0].message.content
            if not summary:
                raise ValueError("AIè¿”å›äº†ç©ºæ‘˜è¦")

            logger.info(f"âœ… AIç”Ÿæˆæ‘˜è¦å®Œæˆ")
            return summary

        except Exception as e:
            logger.error(f"âŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            raise

    def _get_system_prompt(self) -> str:
        """
        è·å–ç³»ç»Ÿæç¤ºè¯

        Returns:
            ç³»ç»Ÿæç¤ºè¯
        """
        from app.prompts.system_prompt import SYSTEM_PROMPT
        return SYSTEM_PROMPT

    def _parse_ai_response(self, content: str) -> dict:
        """
        è§£æAIå“åº”ï¼ˆæå–JSONï¼‰

        Args:
            content: AIè¿”å›çš„åŸå§‹å†…å®¹

        Returns:
            è§£æåçš„å­—å…¸

        Raises:
            ValueError: JSONè§£æå¤±è´¥
        """
        # æå–JSONï¼ˆå¯èƒ½åŒ…å«markdownä»£ç å—ï¼‰
        json_str = self._extract_json(content)
        try:
            result = json.loads(json_str)
            return result
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSONè§£æå¤±è´¥: {e}\nå†…å®¹: {json_str}")
            raise ValueError(f"AIå“åº”æ ¼å¼é”™è¯¯: {e}")

    def _extract_json(self, content: str) -> str:
        """
        ä»AIå“åº”ä¸­æå–JSONå­—ç¬¦ä¸²

        Args:
            content: AIè¿”å›çš„åŸå§‹å†…å®¹

        Returns:
            çº¯å‡€çš„JSONå­—ç¬¦ä¸²
        """
        # ç§»é™¤markdownä»£ç å—æ ‡è®°
        content = content.strip()
        if content.startswith("```json"):
            content = content[7:]
        elif content.startswith("```"):
            content = content[3:]
        if content.endswith("```"):
            content = content[:-3]
        content = content.strip()

        # ä¿®å¤AIå¯èƒ½äº§ç”Ÿçš„éæ ‡å‡†JSONè¯­æ³•
        # ä¾‹å¦‚1: "progress": +30 -> "progress": 30
        # ä¾‹å¦‚2: choice_id: "slack_off" -> choice_id: "slack_off"
        # ä¿®å¤è£¸å­—ç¬¦ä¸²ï¼ˆæ²¡æœ‰å¼•å·çš„å­—ç¬¦ä¸²ï¼‰
        content = re.sub(r'^\s*([^:]+)\s*:\s*"?([^"]+)"?$', r'\1: "\2"', content, flags=re.MULTILINE)
        # ä¿®å¤æ•°å­—å‰çš„åŠ å·ï¼ˆå¦‚: "progress": +30ï¼‰
        content = re.sub(r':\s*\+(\d+)', r': \1', content)
        # ä¿®å¤æ•°å­—å‰çš„å‡å·ï¼ˆå¦‚: "progress": -30ï¼‰
        content = re.sub(r':\s*\-(\d+)', r': -\1', content)
        # ä¿®å¤å¤šä½™çš„å¼•å·å’Œå†’å·ç»„åˆï¼ˆå¦‚: "progress": "value"ï¼‰
        content = re.sub(r'"\s*:', '":', content)
        # é¢å¤–æ¸…ç†ï¼šç§»é™¤å¯èƒ½çš„markdownæ®‹ç•™
        content = re.sub(r'```\w*', '', content)

        return content

    def _generate_fallback_initial(self, seed: int, player_name: str) -> dict:
        """
        ä½¿ç”¨ç´ æåº“ç”Ÿæˆåˆå§‹å†…å®¹ï¼ˆé™çº§æ–¹æ¡ˆï¼‰

        Args:
            seed: éšæœºç§å­
            player_name: ç©å®¶åç§°

        Returns:
            ç´ æåº“ç”Ÿæˆçš„æ¸¸æˆåˆå§‹å†…å®¹
        """
        logger.info(f"ğŸ“¦ ä½¿ç”¨ç´ æåº“ç”Ÿæˆåˆå§‹å†…å®¹ - Seed: {seed}")

        # è·å–éšæœºå…¬å¸ã€NPCã€é­”å¹»å…ƒç´ 
        company = get_random_company(seed)
        npcs = get_random_npcs(seed + 1, count=4)
        magical_element = get_random_magical_element(seed + 2, probability=0.5)
        style = get_style_by_name(company.get("style", "down_to_earth"))

        # æ„å»ºæ¸¸æˆå…ƒæ•°æ®ï¼ˆmagical_levelä½¿ç”¨æ•°å­—æ˜ å°„ï¼‰
        magical_level_map = {0: "none", 1: "light", 2: "medium", 3: "heavy"}
        game_meta = {
            "company_type": company.get("type", "æœªçŸ¥"),
            "style_type": style.get("name", "æ¥åœ°æ°”å¤§ç™½è¯"),
            "magical_level": magical_level_map.get(3 if magical_element else 0, 0),
            "seed_used": seed
        }

        # æ„å»ºå…¬å¸ä¿¡æ¯ï¼ˆåŒ…å«styleå­—æ®µï¼‰
        company_style = get_style_by_name(company.get("style", "down_to_earth"))
        company_info = {
            "name": company.get("name", "æŸå…¬å¸"),
            "type": company.get("type", "unknown"),
            "culture": company.get("culture", "æ™®é€šå…¬å¸æ–‡åŒ–"),
            "atmosphere": company.get("atmosphere", "æ™®é€šåŠå…¬æ°›å›´"),
            "special_rules": company.get("special_rules", []),
            "magical_elements": company.get("magical_elements", []),
            "style": company_style.get("name", "æ¥åœ°æ°”å¤§ç™½è¯")
        }

        # å¦‚æœæœ‰é­”å¹»å…ƒç´ ï¼Œæ·»åŠ åˆ°å…¬å¸ä¿¡æ¯
        if magical_element:
            company_info["magical_elements"].append(magical_element.get("name", "æœªçŸ¥é­”å¹»å…ƒç´ "))

        # æ„å»ºNPCåˆ—è¡¨ï¼ˆç›´æ¥ä½¿ç”¨fallback_libraryè¿”å›çš„å®Œæ•´NPCå¯¹è±¡ï¼‰
        npcs_list = list(npcs)  # fallback_libraryå·²ç»è¿”å›å®Œæ•´NPCå¯¹è±¡

        # æ„å»ºåˆå§‹ç©å®¶çŠ¶æ€
        player_state = {
            "energy": 100,
            "chill": 50,
            "progress": 0,
            "suspicion": 0,
            "connection": 0,
            "blackmail": 0,
            "salary": 5000,
            "reputation": 0,
            "day": 1,
            "week": 1,
            "turn": 0
        }

        # æ„å»ºæ¬¢è¿å‰§æƒ…
        story_context = f"""æ¬¢è¿æ¥åˆ°{company_info['name']}ï¼
{company_info['culture']}
{company_info['atmosphere']}
ä»Šå¤©æ˜¯ä½ çš„ç¬¬ä¸€å¤©ï¼Œä½ æ¥åˆ°äº†å·¥ä½ã€‚ä½œä¸ºä¸€åæ–°å‘˜å·¥ï¼Œä½ éœ€è¦åœ¨è¿™é‡Œç”Ÿå­˜ä¸‹å»ã€‚åœ¨è¿™ä¸ªå……æ»¡æŒ‘æˆ˜çš„èŒåœºä¸­ï¼Œä½ ä¼šé‡åˆ°å„ç§å„æ ·çš„äººå’Œäº‹ã€‚
{f"æ³¨æ„ï¼šè¿™é‡Œä¼¼ä¹æœ‰{magical_element.get('name', 'ä¸€äº›å¥‡æ€ª')}çš„ä¸œè¥¿..." if magical_element else ""}
ç°åœ¨ï¼Œä½ å‡†å¤‡åšä»€ä¹ˆï¼Ÿ"""

        # æ„å»ºåˆå§‹é€‰é¡¹ï¼ˆå¿…é¡»åŒ…å«choice_idï¼‰
        choices = [
            {
                "id": f"choice_work_{seed}",
                "text": "å¼€å§‹å·¥ä½œï¼Œç»™è€æ¿ç•™ä¸‹å¥½å°è±¡",
                "category": "work",
                "effects": {
                    "energy": -10,
                    "chill": 0,
                    "progress": 15,
                    "suspicion": -5,
                    "connection": 5,
                    "blackmail": 0
                },
                "hint": "åŠªåŠ›å·¥ä½œï¼Œæå‡è¿›åº¦å’Œå¥½æ„Ÿ"
            },
            {
                "id": f"choice_slack_{seed}",
                "text": "å…ˆç†Ÿæ‚‰ç¯å¢ƒï¼Œè§‚å¯Ÿä¸€ä¸‹åŒäº‹",
                "category": "slack",
                "effects": {
                    "energy": -5,
                    "chill": 10,
                    "progress": 0,
                    "suspicion": 0,
                    "connection": 10,
                    "blackmail": 0
                },
                "hint": "æ‘¸é±¼è§‚å¯Ÿï¼Œæå‡äººè„‰"
            },
            {
                "id": f"choice_social_{seed}",
                "text": "ä¸»åŠ¨å’ŒåŒäº‹æ‰“æ‹›å‘¼ï¼Œå»ºç«‹å…³ç³»",
                "category": "social",
                "effects": {
                    "energy": -5,
                    "chill": 5,
                    "progress": 0,
                    "suspicion": 0,
                    "connection": 15,
                    "blackmail": 0
                },
                "hint": "ç¤¾äº¤äº’åŠ¨ï¼Œå¿«é€Ÿå»ºç«‹äººè„‰"
            }
        ]

        # è¿”å›å®Œæ•´çš„åˆå§‹å†…å®¹
        return {
            "game_meta": game_meta,
            "company_info": company_info,
            "npcs": npcs_list,
            "player_state": player_state,
            "story": story_context,
            "story_context": story_context,  # æ·»åŠ  story å­—æ®µå…¼å®¹ endpoints.py
            "choices": choices,
            "active_magical_element": magical_element if magical_element else None
        }
